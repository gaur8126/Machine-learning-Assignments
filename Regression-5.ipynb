{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecc588e0-b754-4627-9c14-770568551679",
   "metadata": {},
   "source": [
    "## Q.1\n",
    "\n",
    "1. Elastic Net Regression is a regression technique that combines L1 (Lasso) and L2 (Ridge) regularization penalties.\n",
    "2. It addresses some of the limitations of Lasso and Ridge Regression by providing a balance between variable selection (like Lasso) and handling correlated predictors (like Ridge).\n",
    "3. Elastic Net Regression minimizes the loss function by adding a penalty term that is a combination of both L1 and L2 penalties, controlled by two parameters: \n",
    "α (for the overall strength of regularization) and \n",
    "ρ (for the ratio between L1 and L2 penalties)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dac1a2-84b4-4e30-8511-3e1ac23f6212",
   "metadata": {},
   "source": [
    "## Q.2\n",
    "\n",
    "Optimal values of α and ρ can be chosen using techniques like cross-validation.\n",
    "Grid search or randomized search can be employed to search over a range of values for α and ρ.\n",
    "Cross-validation is performed to evaluate model performance for each combination of α and ρ, and the combination that minimizes prediction error is selected as optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b73d7a-371c-405b-add7-0c58b067612f",
   "metadata": {},
   "source": [
    "## Q.3\n",
    "\n",
    "Advantages:\n",
    "Can handle correlated predictors and multicollinearity effectively.\n",
    "Performs automatic feature selection like Lasso Regression.\n",
    "Provides a balance between bias and variance through the combination of L1 and L2 penalties.\n",
    "Disadvantages:\n",
    "Requires tuning of additional hyperparameters (α and ρ).\n",
    "Computationally more intensive compared to Lasso or Ridge Regression.\n",
    "May not perform well if the dataset is small or the number of predictors is larger than the number of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e56392d-1b6a-43a4-94a2-aa7e8b9e273b",
   "metadata": {},
   "source": [
    "## Q.4\n",
    "\n",
    "1. Prediction tasks where there are a large number of predictors, some of which may be highly correlated.\n",
    "2. High-dimensional datasets where feature selection and regularization are essential.\n",
    "3. Situations where a balance between variable selection and handling multicollinearity is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d207180c-7afd-407a-8cb5-d87351de80f5",
   "metadata": {},
   "source": [
    "## Q.5\n",
    "\n",
    "Interpretation of coefficients in Elastic Net Regression is similar to other regression techniques.\n",
    "Coefficients indicate the magnitude and direction of the relationship between predictors and the target variable.\n",
    "Like Lasso Regression, Elastic Net Regression can set some coefficients to zero, performing automatic feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b22139c-a65a-47bc-be79-bb1d6868831a",
   "metadata": {},
   "source": [
    "## Q.6\n",
    "\n",
    "Missing values can be handled by imputation techniques such as mean, median, or mode imputation, or more sophisticated methods like K-nearest neighbors (KNN) imputation.\n",
    "It's important to handle missing values before applying Elastic Net Regression to avoid bias in the estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21afe95-a14d-4f55-9546-576c230e9b4e",
   "metadata": {},
   "source": [
    "## Q.7\n",
    "\n",
    "Elastic Net Regression performs automatic feature selection by setting some coefficients to zero.\n",
    "By tuning the regularization parameters (α and ρ), you can control the degree of sparsity in the model and thus the number of selected features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284d0fcb-e5aa-4f7c-a70f-fb0a081b0eed",
   "metadata": {},
   "source": [
    "## Q.8\n",
    "\n",
    "You can pickle and unpickle a trained Elastic Net Regression model in Python using the pickle module or the joblib library.\n",
    "Serialize the trained model object using the pickle.dump() or joblib.dump() function.\n",
    "Deserialize the saved model object using the pickle.load() or joblib.load() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177cee29-ae57-48d7-9ebc-8e84f3e65571",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q.9\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
