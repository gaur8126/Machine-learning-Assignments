{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aba5f847-9514-499a-a262-06fde0a0888f",
   "metadata": {},
   "source": [
    "# Q.1 \n",
    "\n",
    "Ensemble is such a technique that combines multiple models --> Train --> Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7954d526-3d39-4c73-8463-54a26df7ae02",
   "metadata": {},
   "source": [
    "# Q.2 \n",
    "\n",
    "Enseble Techniques are used in machien learning so that multiple models can be used together and  improve the model accuracy , robustness, error reduction , overfitting reducing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97900949-df61-413e-95d9-240d09f5beed",
   "metadata": {},
   "source": [
    "# Q.3\n",
    "\n",
    "### Bagging \n",
    "(Bootstrap Aggregating) is an ensemble technique that involves training multiple versions of a model on different subsets of the training data and then combining their predictions. The subsets are created using bootstrap sampling (random sampling with replacement). The final prediction is usually made by averaging the predictions (for regression) or by majority voting (for classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a9f005-6f9d-4dcc-b9da-2f4333107c33",
   "metadata": {},
   "source": [
    "# Q.4 \n",
    "\n",
    "### Boosting\n",
    "Boosting is an ensemble technique that sequentially trains a series of weak learners, with each new model focusing on the mistakes made by the previous ones. The predictions of all the models are then combined to produce the final output. Boosting aims to convert weak learners into strong ones by giving more weight to hard-to-predict instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e5d4f2-57b8-4b52-9942-dd59df9a8e73",
   "metadata": {},
   "source": [
    "# Q.5 \n",
    "\n",
    "#### The benifits of using ensebble technique - \n",
    "1. improve accuracy\n",
    "2. Robust-varience and bias \n",
    "3. Generalized the model \n",
    "4. stability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1881e48-9179-409d-8a56-6f7dd783781e",
   "metadata": {},
   "source": [
    "# Q.6\n",
    "\n",
    "No, ensemble techniques are not always better than individual models. While they often provide improved performance, there are situations where an ensemble might not be necessary or could even perform worse:\n",
    "\n",
    "Simple Problems: For very simple problems, a single model may suffice and perform just as well as an ensemble.\n",
    "Overfitting: If not properly tuned, ensembles can still overfit the training data, especially if the base learners are too complex.\n",
    "Computational Cost: Ensembles can be computationally expensive and require more resources for training and inference.\n",
    "Interpretability: Ensembles, especially those with many base learners, can be less interpretable compared to simpler models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95362e65-66ff-43f2-8f84-fd2b26105763",
   "metadata": {},
   "source": [
    "# Q.7\n",
    "\n",
    "Using bootstrap, the confidence interval for a statistic (e.g., the mean) is calculated by repeatedly resampling the data with replacement to create many \"bootstrap samples.\" The statistic is then computed for each bootstrap sample. The confidence interval is derived from the distribution of these bootstrap statistics, typically by taking the appropriate percentiles (e.g., the 2.5th and 97.5th percentiles for a 95% confidence interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84167153-4b4c-4a29-8617-bc44318c103c",
   "metadata": {},
   "source": [
    "# Q.8\n",
    "\n",
    "Bootstrap is a resampling technique used to estimate statistics on a population by sampling a dataset with replacement. The steps involved in bootstrap are:\n",
    "\n",
    "Original Sample: Start with an original sample of size n.\n",
    "Resampling: Generate a large number of bootstrap samples. Each bootstrap sample is created by randomly sampling n observations from the original sample with replacement.\n",
    "Statistic Calculation: Calculate the statistic of interest (e.g., mean, variance) for each bootstrap sample.\n",
    "Distribution: Use the distribution of the bootstrap statistics to estimate the sampling distribution.\n",
    "Confidence Interval: Determine the confidence interval by taking the appropriate percentiles from the bootstrap distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b716dd-975a-431a-88e0-e243fc48dfc5",
   "metadata": {},
   "source": [
    "# Q.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78c1dc52-c086-4be0-85b9-58829e883f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval: (14.03, 15.06)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# Given data\n",
    "sample_size = 50\n",
    "sample_mean = 15\n",
    "sample_std = 2\n",
    "\n",
    "# Simulate a sample data based on the given mean and standard deviation\n",
    "np.random.seed(42)\n",
    "sample_data = np.random.normal(loc=sample_mean, scale=sample_std, size=sample_size)\n",
    "\n",
    "# Number of bootstrap samples\n",
    "n_bootstraps = 10000\n",
    "\n",
    "# Bootstrap resampling\n",
    "bootstrap_means = []\n",
    "for _ in range(n_bootstraps):\n",
    "    bootstrap_sample = np.random.choice(sample_data, size=sample_size, replace=True)\n",
    "    bootstrap_means.append(np.mean(bootstrap_sample))\n",
    "\n",
    "# Calculate the 95% confidence interval\n",
    "lower_bound = np.percentile(bootstrap_means, 2.5)\n",
    "upper_bound = np.percentile(bootstrap_means, 97.5)\n",
    "\n",
    "print(f\"95% Confidence Interval: ({lower_bound:.2f}, {upper_bound:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8bf5de-4388-4ee0-ad22-7227ff5b17db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
