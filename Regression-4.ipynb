{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5c06368-c1d6-4f57-b456-caebfa14284e",
   "metadata": {},
   "source": [
    "## Q.1\n",
    "\n",
    "Lasso Regression, short for Least Absolute Shrinkage and Selection Operator, is a regression technique that combines ordinary least squares (OLS) regression with regularization. It differs from other regression techniques, such as ordinary linear regression, Ridge Regression, and Elastic Net, primarily in its use of L1 regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b941bcdd-031d-4997-bd69-66cb914e202b",
   "metadata": {},
   "source": [
    "## Q.2  \n",
    "\n",
    "Lasso Regression, short for Least Absolute Shrinkage and Selection Operator, is a regression technique that combines ordinary least squares (OLS) regression with regularization. It differs from other regression techniques, such as ordinary linear regression, Ridge Regression, and Elastic Net, primarily in its use of L1 regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93636ee5-51c6-416b-a038-6d551a838ea2",
   "metadata": {},
   "source": [
    "## Q.3\n",
    "\n",
    "Interpreting the coefficients of a Lasso Regression model involves understanding the impact of each predictor variable on the target variable, considering the regularization effect of L1 regularization\n",
    "\n",
    "1. Magnitude of Coefficients:\n",
    "2. Direction of Coefficients:\n",
    "3. Sparsity and Variable Selection:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d94e05-9453-400b-aff6-b09afd26d866",
   "metadata": {},
   "source": [
    "## Q.4\n",
    "\n",
    "In Lasso Regression, there is typically one main tuning parameter:\n",
    "\n",
    "Regularization Parameter (Œ±):\n",
    "Determines the strength of the penalty term applied to the coefficients.\n",
    "Higher values of ùõº lead to more regularization, resulting in more coefficients being pushed towards zero and potentially more sparsity in the model.\n",
    "Lower values of ùõº reduce the regularization effect, allowing coefficients to take larger magnitudes.\n",
    "Tuning ùõº is crucial for controlling the trade-off between bias and variance in the model. It is often selected through techniques like cross-validation to find the optimal value that minimizes prediction error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eed53eb-f3ba-4514-8ff7-6abf1da1ebfc",
   "metadata": {},
   "source": [
    "## Q.5\n",
    "\n",
    "Yes, Lasso Regression can be adapted for non-linear regression problems using the following main approaches:\n",
    "\n",
    "Feature Engineering:\n",
    "\n",
    "Transforming input features into non-linear forms, such as polynomial features or interaction terms.\n",
    "By creating new features derived from the original ones, Lasso Regression can capture non-linear relationships between predictors and the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd20eed-c7a8-415e-9375-3aa2a0efda19",
   "metadata": {},
   "source": [
    "## Q.6\n",
    "\n",
    "Difference between Ridge regression and lasso regression\n",
    "\n",
    "Ridge Regression: Does not perform variable selection, as it only shrinks the coefficients towards zero without setting them exactly to zero. It retains all predictors in the model.\n",
    "Lasso Regression: Performs variable selection by setting some coefficients to exactly zero. It automatically selects a subset of predictors, effectively performing feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f8bd20-5f6b-46a5-a242-55f9e2f08c0a",
   "metadata": {},
   "source": [
    "## Q.7\n",
    "\n",
    "Yes, Lasso Regression can handle multicollinearity in input features through the following main mechanisms:\n",
    "\n",
    "Automatic Feature Selection:\n",
    "\n",
    "Lasso Regression performs automatic feature selection by setting some coefficients to exactly zero.\n",
    "In the presence of multicollinearity, where predictors are highly correlated, Lasso Regression tends to select one variable from a group of correlated predictors and sets the coefficients of the remaining variables to zero.\n",
    "By excluding redundant predictors, Lasso Regression effectively addresses multicollinearity issues and retains only the most relevant predictors in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497e35a2-57d7-4153-84bf-07317f85eb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q.8 \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
